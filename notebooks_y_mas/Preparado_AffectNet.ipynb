{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagenes/preparado_aff.jpeg\" alt=\"Imagen creada con inteligencia artificial y editada con Microsoft Paint\" style=\"border-radius: 15px\">\n",
    "\n",
    "\n",
    "*Imagen creada con inteligencia artificial.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **INTRODUCCIÓN**\n",
    "\n",
    "El **dataset** **‘fer2013’** se presenta en un archivo **CSV** en el cual no tenemos las **fotografías**, sino que tenemos una columna, ‘**pixels**’, que contiene una cadena de números separados por espacios, siendo estos números los colores (en escala de grises) de las **fotografías**. **A partir** de las **fotografías** del dataset **'AffectNet'** crearemos **7 datasets**, uno por cada **expresión facial**, y al final los uniremos para que tengan un formato similar a **'FER2013'**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BIBLIOTECAS USADAS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CODIGO COLUMNAS 'emotion' Y 'pixels'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_base = \"datos/AffectNet/AffectNet_original/archive/\"\n",
    "def leer_imagenes(carpeta):\n",
    "    lista_imagenes = []\n",
    "    ruta_carpeta = os.path.join(ruta_base, str(carpeta))\n",
    "    for filename in os.listdir(ruta_carpeta):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            ruta_imagen = os.path.join(ruta_carpeta, filename)\n",
    "            img = cv2.imread(ruta_imagen, cv2.IMREAD_GRAYSCALE)  \n",
    "            img_resized = cv2.resize(img, (48, 48)) \n",
    "            img_string = ' '.join(map(str, img_resized.flatten()))  \n",
    "            lista_imagenes.append(img_string)\n",
    "    return lista_imagenes\n",
    "\n",
    "df_5= pd.DataFrame(columns=['emotion', 'pixels']) #Iremos cambiado el nombre del dataframe\n",
    "df_5['emotion'] = [5] * len(os.listdir(os.path.join(ruta_base, \"5\"))) #Cambiar el nombre del dataframe, el numero entre corchetes y el que sigue a ruta base.\n",
    "df_5['pixels'] = leer_imagenes(5)#Iremos cambiado el nombre del dataframe y el numero entre parentesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">La función **leer_imagenes** procesa imágenes a partir de una carpeta especificada. Cada imagen se carga en color, luego se convierte a escala de grises, se redimensiona a 48x48 píxeles y se convierte en una cadena de píxeles. Estas cadenas se almacenan en una lista que se devuelve como resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CODIGO COLUMNA 'Usage'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(df_5) #Iremos cambiado el nombre del dataframe\n",
    "\n",
    "num_training = int(np.ceil(0.8 * total_rows))  \n",
    "num_public_test = int(np.floor(0.1 * total_rows))  \n",
    "num_private_test = total_rows - num_training - num_public_test\n",
    "\n",
    "while num_training + num_public_test + num_private_test != total_rows:\n",
    "    num_training += 1\n",
    "\n",
    "usage_values = np.array(['Training'] * num_training + ['PublicTest'] * num_public_test + ['PrivateTest'] * num_private_test)\n",
    "\n",
    "\n",
    "np.random.seed(42)  \n",
    "df_5['Usage'] = np.random.choice(usage_values, size=total_rows, replace=False)#Iremos cambiado el nombre del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Se asignan etiquetas de uso ('Training', 'PublicTest', 'PrivateTest') a las filas del DataFrame df_6 basándose en porcentajes predefinidos (80%, 10%, 10%). Se utiliza una semilla aleatoria para garantizar la aleatoriedad en la asignación de etiquetas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **COMPROBACION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_filas = df_4.shape[0] #Iremos cambiado el nombre del dataframe\\nprint(f\"El DataFrame tiene {num_filas} filas.\")'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"num_filas = df_4.shape[0] #Iremos cambiado el nombre del dataframe\n",
    "print(f\"El DataFrame tiene {num_filas} filas.\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Vemos que hay tantas filas como fotografias hay en la carpeta correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_4['Usage'].value_counts(True)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"df_4['Usage'].value_counts(True)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Queda muy balanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Obtener el tamaño en píxeles de las imágenes\\ndf_4[\\'num_pixels\\'] = df_4[\\'pixels\\'].apply(lambda x: len(x.split()))\\n\\n# Calcular estadísticas sobre el tamaño en píxeles\\nmin_pixels = df_4[\\'num_pixels\\'].min()\\nmax_pixels = df_4[\\'num_pixels\\'].max()\\n\\n\\nprint(f\"Tamaño mínimo de imagen en píxeles: {min_pixels}\")\\nprint(f\"Tamaño máximo de imagen en píxeles: {max_pixels}\")\\n\\nprint(f\"Por lo que las imagenes son de {int(math.sqrt(max_pixels))}x{int(math.sqrt(max_pixels))} \")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Obtener el tamaño en píxeles de las imágenes\n",
    "df_4['num_pixels'] = df_4['pixels'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Calcular estadísticas sobre el tamaño en píxeles\n",
    "min_pixels = df_4['num_pixels'].min()\n",
    "max_pixels = df_4['num_pixels'].max()\n",
    "\n",
    "\n",
    "print(f\"Tamaño mínimo de imagen en píxeles: {min_pixels}\")\n",
    "print(f\"Tamaño máximo de imagen en píxeles: {max_pixels}\")\n",
    "\n",
    "print(f\"Por lo que las imagenes son de {int(math.sqrt(max_pixels))}x{int(math.sqrt(max_pixels))} \")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ejemplo_pixels = df_4[\\'pixels\\'].iloc[0] #Sabemos que todas las filas, tienen las misma caracteristicas, asi que cogemos una cualquiera.\\n\\n# Dividimos la cadena de píxeles en valores individuales y convertimos a enteros\\nvalores_pixeles = list(map(int, ejemplo_pixels.split()))\\n\\n# Verificamos si todos los valores están dentro del rango de 0 a 255\\ntodos_en_rango = all(0 <= pixel <= 255 for pixel in valores_pixeles)\\n\\nif todos_en_rango:\\n    print(\"Las imágenes del dataset \\'df_4\\' son en escala de grises.\")\\nelse:\\n    print(\"Las imágenes del dataset \\'df_4\\' son a color (o tienen valores fuera del rango 0-255).\")'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ejemplo_pixels = df_4['pixels'].iloc[0] #Sabemos que todas las filas, tienen las misma caracteristicas, asi que cogemos una cualquiera.\n",
    "\n",
    "# Dividimos la cadena de píxeles en valores individuales y convertimos a enteros\n",
    "valores_pixeles = list(map(int, ejemplo_pixels.split()))\n",
    "\n",
    "# Verificamos si todos los valores están dentro del rango de 0 a 255\n",
    "todos_en_rango = all(0 <= pixel <= 255 for pixel in valores_pixeles)\n",
    "\n",
    "if todos_en_rango:\n",
    "    print(\"Las imágenes del dataset 'df_4' son en escala de grises.\")\n",
    "else:\n",
    "    print(\"Las imágenes del dataset 'df_4' son a color (o tienen valores fuera del rango 0-255).\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Puedes descomentar estas comprobaciones y verificar que está saliendo bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GUARDADO DEL DATAFRAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.to_csv('datos/AffectNet/expresiones individuales/df_5.csv', index=False) #Iremos cambiado el nombre del dataframe y del bombre con el que lo guardamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>61 62 63 63 64 65 65 64 65 65 65 65 65 65 65 6...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>220 221 222 220 220 219 214 215 213 213 213 21...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>69 58 68 68 60 62 73 60 56 54 52 50 49 58 50 4...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>69 68 68 68 69 68 68 69 69 69 69 68 68 67 67 6...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>238 241 241 240 240 245 243 238 234 232 227 22...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        5  61 62 63 63 64 65 65 64 65 65 65 65 65 65 65 6...  Training\n",
       "1        5  220 221 222 220 220 219 214 215 213 213 213 21...  Training\n",
       "2        5  69 58 68 68 60 62 73 60 56 54 52 50 49 58 50 4...  Training\n",
       "3        5  69 68 68 68 69 68 68 69 69 69 69 68 68 67 67 6...  Training\n",
       "4        5  238 241 241 240 240 245 243 238 234 232 227 22...  Training"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CONCATENADO Y GUARDADO DE LOS DATASETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df_0 = pd.read_csv('datos/AffectNet/expresiones individuales/df_0.csv')\n",
    "df_1 = pd.read_csv('datos/AffectNet/expresiones individuales/df_1.csv')\n",
    "df_2 = pd.read_csv('datos/AffectNet/expresiones individuales/df_2.csv')\n",
    "df_3 = pd.read_csv('datos/AffectNet/expresiones individuales/df_3.csv')\n",
    "df_4 = pd.read_csv('datos/AffectNet/expresiones individuales/df_4.csv')\n",
    "df_5 = pd.read_csv('datos/AffectNet/expresiones individuales/df_5.csv')\n",
    "df_6 = pd.read_csv('datos/AffectNet/expresiones individuales/df_6.csv') \n",
    "\n",
    "df_unido = pd.concat([df_0,df_1, df_2, df_3, df_4, df_5, df_6], ignore_index=True) \n",
    "\n",
    "df_unido.to_csv('datos/AffectNet/df_AffectNet_formato.csv', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **COMENTARIO FINAL**\n",
    "\n",
    "**Reconocer expresiones faciales** no es una tarea fácil para una red neuronal. A los **humanos** nos resulta relativamente sencilla dicha tarea, pero aunque las redes neuronales intentan imitar el **cerebro** humano, estas pueden tener dificultades para alcanzar precisiones altas en dicha tarea.   \n",
    "\n",
    "El dataset \"**FER2013**\" es bastante reconocido, es de fácil acceso y **ha sido muy usado para entrenar distintos modelos**, por esto es **la base** del presente proyecto. La parte negativa es que pese a ser un buen dataset, se queda corto, no es facil obtener buenos resultados, al menos no con ordenadores domesticos. Después de balancearlo usando métodos de data augmentation, no logramos alcanzar precisiones que satisfarían nuestras expectativas. Podríamos haber continuado con más procesos de data augmentation, pero esto supondría únicamente cambios en las mismas fotografías, lo que podría llevar, con bastante seguridad, a que el modelo generalice mal. Sería algo así como enseñar a alguien que nunca ha visto un perro lo que es un perro mostrándole únicamente fotografías de yorkshires y chihuahuas… ¿**Reconocería** un mastín como un perro? ¿Y una hiena o un lobo? Para solventar esto y tras una investigación, encontramos esta [versión](https://www.kaggle.com/datasets/noamsegal/affectnet-training-data) del dataset '**AffectNet**'. La version completa de \"**AffectNet**\" es demasiado grande para trabajar con el con un ordenador personal, en cambio la version con la que estamos trabajando resulta casi idonea, tiene  las mismas etiquetas (realmente una más, '**contempt**', que significa 'desprecio' o 'desdén') solo que, a diferencia de \"**fer2013**\", no teníamos un csv con tres columnas: la etiqueta de la emoción, la cadena que representa los píxeles y una tercera para el uso de cada fotografía. Precisamente esto es lo que se ha abordado en este notebook: tener un dataset con el mismo formato que '**fer2013**' para poder unirlos y entrenar un modelo con mayor variedad de entradas, permitiendo así un mejor aprendizaje.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
